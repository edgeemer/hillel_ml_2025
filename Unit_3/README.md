# Завдання
1. Допишіть в файлі `kfold.py` функції `kfold_cross_validation` та `evaluate_accuracy` - ✅
2. Порахуйте для різних `k` в `KNN` точність на **тестовому** датасеті і запишіть в `README.md` - ✅
# Accuracy Results for Different Values of k in KNN
| **k**  | **Accuracy** |
|--------|--------------|
| 3      | 0.82         |
| 4      | 0.83         |
| 5      | 0.83         |
| 6      | 0.83         |
| 7      | 0.81         |
| 9      | 0.80         |
| 10     | 0.81         |
| 15     | 0.79         |
| 20     | 0.78         |
| 21     | 0.78         |
| 40     | 0.73         |
| 41     | 0.73         |
3. Які можна зробити висновки про вибір `k`? - ✅ <br>
  `Найвища точність (0,83)` при значеннях `k=4,5, 6` => найкращий `баланс` між bias і variance. <br>
  Коли `k > 6`, точність починає поступово знижуватися (bias росте та `модель втрачає можливість захоплювати локальні патерни`). <br>
  `k=3` має дещо нижчу точність (0,82) => `оверфітинг або недостатньо даних`.

4. Знайшовши найкращий `k` змініть `num_folds` (в `main()`) та подивіться чи в середньому точність на валідаційних датасетах схожа з точністю на тестовому датасеті. - ✅<br>
   Для `k=4` - ідентична, для `k=5, 6` - трішки нижча

  |**k=1**| **Accuracy** |**k=4**| **Accuracy** |
  |-------|--------------|-------|--------------|
  |  1    |    0.87      |  1    |    0.87      |
  |  2    |    0.90      |  2    |    0.89      |
  |  3    |    0.84      |  3    |    0.85      |
  |  4    |    0.85      |  4    |    0.85      |
  |  5    |    0.86      |  5    |    0.86      |
