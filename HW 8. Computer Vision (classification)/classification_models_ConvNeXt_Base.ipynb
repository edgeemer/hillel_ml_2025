{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edgeemer/hillel_ml_2025/blob/main/HW%208.%20Computer%20Vision%20(classification)/classification_models_ConvNeXt_Base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNVJ9YGnI7lO"
      },
      "outputs": [],
      "source": [
        "%pip install albumentations datasets > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ab30W1ZFI_YA"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "import struct\n",
        "from typing import List\n",
        "\n",
        "import albumentations as albu  # Library for image augmentation\n",
        "import cv2  # OpenCV library for image processing\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # Library for progress bars\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader  # PyTorch utilities for data handling\n",
        "import torchvision.models as models  # Pre-trained models provided by PyTorch\n",
        "\n",
        "from datasets import load_dataset  # Custom function to load dataset\n",
        "\n",
        "import matplotlib.pyplot as plt  # Library for plotting graphs and images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88IUKqnqI9wM"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)  # Set random seed for reproducibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJuh10DLKzL-"
      },
      "source": [
        "## Dataset - [Tiny ImageNet](https://huggingface.co/datasets/zh-plus/tiny-imagenet)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irVDw1j_JdEU"
      },
      "outputs": [],
      "source": [
        "# Load the dataset using the load_dataset function with parameters \"frgfm/imagenette\" and \"320px\".\n",
        "# The \"frgfm/imagenette\" dataset is being loaded with images resized to 320 pixels.\n",
        "dataset = load_dataset(\"frgfm/imagenette\", \"320px\")\n",
        "\n",
        "# Define the number of labels in the dataset.\n",
        "num_labels = 10\n",
        "\n",
        "# Print the dataset object.\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7Bi6CddXNsp"
      },
      "outputs": [],
      "source": [
        "# Access the training split of the dataset using the key \"train\".\n",
        "# Then, access the 124th sample (indexing is 0-based) within the training split.\n",
        "# Retrieve the image data associated with the sample.\n",
        "image_data = dataset[\"train\"][123][\"image\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVElCdhCKcLG"
      },
      "outputs": [],
      "source": [
        "class HuggingFaceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Define a custom dataset class named HuggingFaceDataset inheriting from the PyTorch Dataset class.\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset, augmentations: albu.Compose, input_shape: tuple) -> None:\n",
        "        # Constructor method to initialize the dataset and augmentation transformations.\n",
        "        self.dataset = dataset  # Store the input dataset\n",
        "        self.augs = augmentations  # Store the augmentation transformations\n",
        "        self.input_shape = input_shape # Store the input shape\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        # Override the len method to return the length of the dataset.\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index) -> tuple:\n",
        "        # Override the getitem method to retrieve a sample from the dataset.\n",
        "        sample = self.dataset[index]  # Get the sample at the specified index from the dataset\n",
        "\n",
        "        # Convert the image to RGB format if it's not already in that format\n",
        "        image = sample[\"image\"].convert(\"RGB\")\n",
        "\n",
        "        # Apply the specified augmentations to the image\n",
        "        image = self.augs(image=np.array(image))[\"image\"]\n",
        "\n",
        "        # Convert the augmented image to a PyTorch tensor and permute its dimensions\n",
        "        image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        # Convert the label to a PyTorch LongTensor\n",
        "        label = torch.LongTensor([sample[\"label\"]])\n",
        "\n",
        "        # Return the augmented image and its corresponding label as a tuple\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n27A03_0I9wQ",
        "outputId": "0e63043b-e5f8-4be9-b78f-5c974dadcc9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:58: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Set the batch size for training\n",
        "batch_size = 32\n",
        "\n",
        "# Define the input shape for the images (height, width).\n",
        "# NOTE: To speed up training, you can decrease the input shape, but it may affect the final performance.\n",
        "input_shape = (224, 224)\n",
        "\n",
        "# Set the number of workers for data loading to be the number of available CPU cores\n",
        "# workers = os.cpu_count() (error)\n",
        "workers = 0\n",
        "\n",
        "# Define the augmentation transformations for training images\n",
        "# TODO: optional, play with augmentations\n",
        "train_augs = albu.Compose([\n",
        "    albu.Resize(input_shape[0], input_shape[1]), # Resize before other transformations\n",
        "    albu.HorizontalFlip(p=0.5),  # Randomly flip images horizontally\n",
        "    albu.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5), # Randomly shift, scale, and rotate\n",
        "    albu.Normalize()  # Normalize image pixel values to a standard range\n",
        "])\n",
        "\n",
        "# Create a DataLoader for training data using the defined augmentations\n",
        "train_loader = DataLoader(\n",
        "    HuggingFaceDataset(dataset['train'], train_augs, input_shape=input_shape), # Pass input_shape\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=workers\n",
        ")\n",
        "\n",
        "# Define the augmentation transformations for validation images\n",
        "valid_augs = albu.Compose([\n",
        "    albu.Resize(input_shape[0], input_shape[1]), # Resize before normalization\n",
        "    albu.Normalize()  # Only normalize for validation\n",
        "])\n",
        "\n",
        "# Create a DataLoader for validation data using the defined augmentations\n",
        "valid_loader = DataLoader(\n",
        "    HuggingFaceDataset(dataset['validation'], valid_augs, input_shape=input_shape), # Pass input_shape\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=workers\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPlSx5w6I9wR"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    device: str = \"cpu\",\n",
        "    verbose: bool = True,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Function to train the model for one epoch.\n",
        "\n",
        "    Args:\n",
        "    - model: The neural network model to be trained.\n",
        "    - loader: DataLoader object for loading the training data.\n",
        "    - criterion: Loss function criterion.\n",
        "    - optimizer: Optimizer for updating model parameters.\n",
        "    - device: Device to run the model on (default is \"cpu\").\n",
        "    - verbose: If True, print progress during training.\n",
        "\n",
        "    Returns:\n",
        "    - logs: Dictionary containing training statistics.\n",
        "    \"\"\"\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    logs = {\"train_loss\": [], \"accuracies\": []}\n",
        "\n",
        "    loop = tqdm(loader, disable=not verbose, file=sys.stdout, desc='Training')\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(loop):\n",
        "        inputs, targets = inputs.to(device), targets.to(device) # Move data to the device\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients from the previous iteration\n",
        "        outputs = model(inputs)  # Forward pass: get model predictions\n",
        "        loss = criterion(outputs, targets.squeeze())  # Calculate the loss\n",
        "        loss.backward()  # Backpropagation: calculate gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        # Logging and progress updates\n",
        "        logs[\"train_loss\"].append(loss.item()) # Store the training loss for the batch\n",
        "        _, predicted = torch.max(outputs, 1) # Get the predicted class labels\n",
        "        accuracy = (predicted == targets.squeeze()).sum().item() / targets.size(0)  # Calculate the accuracy for the batch\n",
        "        logs[\"accuracies\"].append(accuracy) # Store the accuracy for the batch\n",
        "\n",
        "        loop.set_postfix({'loss': loss.item(), 'acc': accuracy})  # Update progress bar (optional)\n",
        "\n",
        "\n",
        "    # TODO: complete training function\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cyauJBBI9wR"
      },
      "outputs": [],
      "source": [
        "@torch.inference_mode()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: str = \"cpu\",\n",
        "    verbose: bool = True,\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Function to evaluate the model on the validation or test set.\n",
        "\n",
        "    Args:\n",
        "    - model: The neural network model to be evaluated.\n",
        "    - loader: DataLoader object for loading the validation or test data.\n",
        "    - criterion: Loss function criterion.\n",
        "    - device: Device to run the model on (default is \"cpu\").\n",
        "    - verbose: If True, print evaluation results.\n",
        "\n",
        "    Returns:\n",
        "    - logs: Dictionary containing evaluation statistics.\n",
        "    \"\"\"\n",
        "    # TODO: complete evaluation function\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    logs = {\"eval_loss\": [], \"accuracy\": 0}\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    loop = tqdm(loader, disable=not verbose, file=sys.stdout, desc='Evaluating')\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(loop):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        outputs = model(inputs)  # Get model predictions\n",
        "        loss = criterion(outputs, targets.squeeze())  # Calculate loss\n",
        "\n",
        "        # Update evaluation metrics\n",
        "        logs[\"eval_loss\"].append(loss.item())\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total_correct += (predicted == targets.squeeze()).sum().item()\n",
        "        total_samples += targets.size(0)\n",
        "\n",
        "        loop.set_postfix({'loss': loss.item()})\n",
        "\n",
        "    logs[\"accuracy\"] = total_correct / total_samples  # Calculate overall accuracy\n",
        "\n",
        "    return logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMCu4G23I9wS"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA (GPU) is available, otherwise use CPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device - {device}\\n\")\n",
        "\n",
        "# TODO: Find a model that gives the best score.\n",
        "# https://pytorch.org/vision/stable/models.html\n",
        "# https://pytorch.org/vision/stable/models/generated/torchvision.models.convnext_base.html#torchvision.models.convnext_base\n",
        "\n",
        "model = models.convnext_base(weights=models.ConvNeXt_Base_Weights.IMAGENET1K_V1)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_labels)\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Number of trainable parameters -\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
        "\n",
        "# Define the optimizer for updating model parameters\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3) # Have shown great speed/efficiency in the previous HW\n",
        "\n",
        "# Define the loss function\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL1HDRniI9wT"
      },
      "outputs": [],
      "source": [
        "n_epochs = 20  # Number of epochs for training\n",
        "\n",
        "train_losses = []  # List to store training losses for each epoch\n",
        "train_accuracies = []  # List to store training accuracies for each epoch\n",
        "\n",
        "valid_losses = []  # List to store validation losses for each epoch\n",
        "valid_accuracies = []  # List to store validation accuracies for each epoch\n",
        "\n",
        "# Loop through each epoch\n",
        "for ep in range(n_epochs):\n",
        "    print(f\"\\nEpoch {ep + 1:2d}/{n_epochs:2d}\")\n",
        "\n",
        "    # Train the model for one epoch and collect training statistics\n",
        "    train_logs = train_one_epoch(model, train_loader, loss_fn, optimizer, device, verbose=True)\n",
        "    train_losses.append(np.mean(train_logs[\"train_loss\"]))\n",
        "    train_accuracies.append(np.mean(train_logs[\"accuracies\"]))\n",
        "    print(\"      loss:\", train_losses[-1])\n",
        "    print(\"  accuracy:\", train_accuracies[-1])\n",
        "\n",
        "    # Evaluate the model on the validation set and collect evaluation statistics\n",
        "    valid_logs = evaluate(model, valid_loader, loss_fn, device, verbose=True)\n",
        "    valid_losses.append(np.mean(valid_logs[\"eval_loss\"]))  # Append the validation loss for the epoch\n",
        "    valid_accuracies.append(np.mean(valid_logs[\"accuracy\"]))  # Append the validation accuracy for the epoch\n",
        "    print(\"      loss:\", valid_losses[-1])  # Print the validation loss for the epoch\n",
        "    print(\"  accuracy:\", valid_accuracies[-1])  # Print the validation accuracy for the epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-k-4YArI9wT"
      },
      "outputs": [],
      "source": [
        "# Create a figure with two subplots side by side\n",
        "fix, axes = plt.subplots(ncols=2, figsize=(15, 4))\n",
        "\n",
        "# Plot the training and validation losses on the first subplot (axes[0])\n",
        "axes[0].plot(np.arange(len(train_losses)), train_losses, \".-\")  # Plot training losses\n",
        "axes[0].plot(np.arange(len(valid_losses)), valid_losses, \".-\")  # Plot validation losses\n",
        "axes[0].legend([\"train\", \"validation\"])  # Add legend to distinguish between training and validation losses\n",
        "axes[0].set_title(\"Loss\")  # Set title for the subplot as \"Loss\"\n",
        "axes[0].grid()  # Add grid lines to the plot\n",
        "\n",
        "# Plot the training and validation accuracies on the second subplot (axes[1])\n",
        "axes[1].plot(np.arange(len(train_accuracies)), train_accuracies, \".-\")  # Plot training accuracies\n",
        "axes[1].plot(np.arange(len(valid_accuracies)), valid_accuracies, \".-\")  # Plot validation accuracies\n",
        "axes[1].legend([\"train\", \"validation\"])  # Add legend to distinguish between training and validation accuracies\n",
        "axes[1].set_title(\"Accuracy\")  # Set title for the subplot as \"Accuracy\"\n",
        "axes[1].grid();  # Add grid lines to the plot"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}