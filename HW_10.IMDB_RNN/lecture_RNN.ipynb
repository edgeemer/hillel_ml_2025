{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b50234f0-aa06-4ee6-b0dd-8f2503b79f98",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Рекурентна нейронна мережа (RNN) - це клас штучних нейронних мереж, призначених для обробки послідовних даних і врахування контексту з попередніх кроків. Основна особливість RNN полягає в тому, що вона має внутрішні зв'язки, що дозволяють інформації передаватися від одного кроку до наступного в послідовності даних.\n",
    "\n",
    "Кожен елемент послідовності обробляється RNN на основі вхідних даних та внутрішнього стану (попередньої інформації). Це дозволяє RNN утримувати певний контекст та використовувати його для передбачення або класифікації наступного елемента в послідовності.\n",
    "\n",
    "Однак стандартні RNN мають певні недоліки, такі як проблема зі зниклим градієнтом, яка може утруднювати навчання на довгих послідовностях. Тому було розроблено різноманітні модифікації RNN, такі як Long Short-Term Memory (LSTM) та Gated Recurrent Unit (GRU), які допомагають подолати ці обмеження.\n",
    "\n",
    "У сфері штучного інтелекту, що постійно розширюється, аналіз і прогнозування послідовних даних залишаються ключовими зусиллями. Це насамперед тому, що численні аспекти реального світу, такі як мова, дані часових рядів природно існують у послідовності. Розуміння цих послідовностей і передбачення майбутніх подій на основі минулих даних є основою багатьох сучасних систем ШІ. Recurrent Neural Networks (RNN), клас штучних нейронних мереж, призначених явно для розпізнавання шаблонів у послідовностях даних.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/sequential_problems.png\" height=300 width=700>\n",
    "</center>\n",
    "\n",
    "Перш ніж ми заглибимося в RNN, давайте спочатку зрозуміємо, чому вони необхідні. У багатьох випадках інформація, що передається, не є ізольованою, а радше залежить від серії попередніх елементів. Традиційні нейронні мережі, включаючи мережі прямого зв’язку, мають тенденцію розглядати вхідні дані незалежно, позбавлені будь-якого послідовного контексту. Це обмеження стає особливо помітним у таких завданнях, як моделювання мови, де значення слова часто глибоко переплітається з його попередніми словами. Отже, механізм «пригадування» або розгляду минулої інформації стає вирішальним.\n",
    "\n",
    "## Basic RNNs\n",
    "\n",
    "На цьому етапі в гру вступають RNN, призначені для вирішення вищезгаданого обмеження. RNN створюють петлю в мережі, що забезпечує постійність інформації. По суті, це означає, що мережа має форму пам’яті, яка допомагає зберігати інформацію про попередні вхідні дані під час обробки нових.\n",
    "\n",
    "Давайте зануримося в деталі. RNN — це клас нейронних мереж, які дозволяють використовувати попередні виходи як вхідні, маючи приховані стани. Зазвичай вони такі:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/architecture-rnn-ltr.png\", height=400 width=800>\n",
    "</center>\n",
    "\n",
    "Для кожного тимчасового кроку $t$ активація $a^{<t>}$ і результат $y^{<t>}$ виражаються таким чином:\n",
    "\n",
    "$$ a^{<t>} = g_1(W_{aa} a^{<t - 1>} + W_{ax} x^{<t>} + b_a) $$\n",
    "$$ y^{<t>} = g_2(W_{ya} a^{<t>} + b_y) $$\n",
    "\n",
    "де $W_{ax}$, $W_{aa}$, $W_{ya}$, $b_{a}$, $b_{y}$ це коефіцієнти, які спільно використовуються в часі, і функції активації $g_1$, $g_2$.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/description-block-rnn-ltr.png\" height=400 width=800>\n",
    "</center>\n",
    "\n",
    "Рекурентна нейронна мережа — це нейронна мережа, яка спеціалізується на обробці послідовності даних $x(t)= x(1), . . . , x(τ)$ з індексом кроку за часом $t$ від $1$ до $τ$ (tau). Для завдань, які передбачають послідовне введення, наприклад мова, часто краще використовувати RNN. У задачі НЛП, якщо ви хочете передбачити наступне слово в реченні, важливо знати слова перед ним. RNN називають рекурентними, тому що вони виконують одне й те саме завдання для кожного елемента послідовності, при цьому результат залежить від попередніх обчислень. Інший спосіб думати про RNN полягає в тому, що вони мають «пам’ять», яка фіксує інформацію про те, що було обчислено до цього часу.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/CleanShot 2023-12-04 at 15.36.10.png\">\n",
    "</center>\n",
    "\n",
    "У лівій частині наведеної вище діаграми показано позначення RNN, а в правій частині RNN розгортається у повну мережу. Під розгортанням ми маємо на увазі, що ми записуємо мережу для повної послідовності. Наприклад, якщо послідовність, яка нас цікавить, є реченням із 3 слів, мережа буде розгорнута в 3-рівневу нейронну мережу, по одному шару для кожного слова.\n",
    "\n",
    "**Вхідні дані**: $x(t)$​ береться як вхідні дані для мережі на кроці часу $t$. Наприклад, $x1$ може бути вектором з одноразовим використанням, що відповідає слову речення.\n",
    "\n",
    "**Прихований стан**: $h(t)$​ представляє прихований стан у момент часу $t$ і діє як «пам’ять» мережі. $h(t)$​ обчислюється на основі поточного введення та прихованого стану попереднього кроку часу: $h(t)​ = f(U x(t)​ + W h(t−1)​)$. Функція $f$ вважається нелінійним перетворенням, таким як `tanh`, `ReLU`.\n",
    "\n",
    "**Вагові коефіцієнти**: RNN має вхідні дані для прихованих зв’язків, параметризованих ваговою матрицею $U$, повторювані зв’язки «від прихованих до прихованих», параметризованих ваговою матрицею $W$, і приховані вихідні зв’язки, параметризовані ваговою матрицею $V$ і всіма цими ваговими коефіцієнтами $(U, V, W)$ поділяються в часі.\n",
    "\n",
    "**Вихід**: $o(t)$​ ілюструє вихід мережі.\n",
    "\n",
    "### Forward Pass\n",
    "\n",
    "На малюнку не вказано вибір функції активації для прихованих одиниць. Перш ніж продовжити, ми зробимо кілька припущень:\n",
    "1) ми припустимо функцію активації гіперболічного тангенса для прихованого шару.\n",
    "2) Ми припускаємо, що вихід є дискретним, ніби RNN використовується для передбачення слів або символів. Природний спосіб представлення дискретних змінних полягає в тому, щоб розглядати результат $o$ як такий, що дає ненормализовані логарифмічні ймовірності кожного можливого значення дискретної змінної. Потім ми можемо застосувати операцію `softmax` як етап постобробки, щоб отримати вектор $ŷ$ нормалізованих ймовірностей над результатом.\n",
    "\n",
    "Таким чином, прямий прохід RNN може бути представлений наведеним нижче набором рівнянь.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/1.png\">\n",
    "</center>\n",
    "\n",
    "Це приклад рекурентної мережі, яка відображає вхідну послідовність у вихідну послідовність такої ж довжини. Тоді загальні втрати для даної послідовності значень $x$ у поєднанні з послідовністю значень $y$ будуть лише сумою втрат за всі часові кроки. Ми припускаємо, що виходи $o(t)$ використовуються як аргументи функції `softmax` для отримання вектора ймовірностей над виходом. Ми також припускаємо, що втрата $L$ є негативним логарифмом правдоподібності справжньої цілі $y(t)$, враховуючи вхідні дані до цього часу.\n",
    "\n",
    "### Backward Pass\n",
    "\n",
    "Обчислення градієнта передбачає виконання прямого проходу розповсюдження, що рухається зліва направо через графік, показаний вище, а потім зворотного проходу розповсюдження, що рухається справа наліво через графік. Час виконання дорівнює $O(τ)$ і не може бути зменшений розпаралелюванням, оскільки граф прямого поширення за своєю суттю є послідовним; кожен часовий крок може бути обчислений лише після попереднього. Стани, обчислені в прямому проході, повинні зберігатися, доки вони не будуть повторно використані під час зворотного проходу, тому вартість пам’яті також дорівнює $O(τ)$. Алгоритм зворотного поширення, застосований до розгорнутого графіка з вартістю $O(τ)$, називається зворотним поширенням у часі (Backpropagation Through Time - BPTT). Оскільки параметри спільні для всіх часових кроків у мережі, градієнт на кожному виході залежить не лише від обчислень поточного, але й попередніх часових кроків.\n",
    "\n",
    "### Computing Gradients\n",
    "\n",
    "Враховуючи нашу функцію втрат $L$, нам потрібно обчислити градієнти для наших трьох вагових матриць $U, V, W$ і членів зсуву $b, c$ і оновити їх за допомогою швидкості навчання $α$. Подібно до нормального зворотного поширення, градієнт дає нам уявлення про те, як змінюються втрати щодо кожного вагового параметра. Ми оновлюємо ваги $W$, щоб мінімізувати втрати за допомогою наступного рівняння:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/2.png\">\n",
    "</center>\n",
    "\n",
    "Те ж саме потрібно зробити для інших ваг $U, V, b, c$.\n",
    "\n",
    "Давайте тепер обчислимо градієнти за допомогою BPTT для наведених вище рівнянь RNN. Вузли нашого обчислювального графа включають параметри $U, V, W, b і c$, а також послідовність вузлів, індексованих $t$ для $x(t)$, $h(t)$, $o(t)$ і $L(t)$. Для кожного вузла $n$ нам потрібно рекурсивно обчислити градієнт $∇nL$ на основі градієнта, обчисленого у вузлах, які слідують за ним на графіку.\n",
    "\n",
    "Градієнт щодо виходу $o(t)$ обчислюється за умови, що $o(t)$ використовується як аргумент функції softmax для отримання вектора $ŷ$ ймовірностей над виходом. Ми також припускаємо, що втрата – це від’ємна логарифмічна ймовірність справжньої цілі $y(t)$.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/3.png\">\n",
    "</center>\n",
    "\n",
    "Давайте тепер зрозуміємо, як градієнт протікає через прихований стан $h(t)$. Це ми можемо чітко бачити з наведеної нижче діаграми, що в момент часу $t$ прихований стан $h(t)$ має градієнт, що випливає як від поточного виходу, так і від наступного прихованого стану.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/4.png\">\n",
    "</center>\n",
    "\n",
    "Ми йдемо назад, починаючи з кінця послідовності. На останньому часовому кроці $τ$, $h(τ)$ має лише $o(τ)$ як нащадка, тому його градієнт простий:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/5.png\">\n",
    "</center>\n",
    "\n",
    "Потім ми можемо виконати ітерацію назад у часі для зворотного поширення градієнтів у часі від $t=τ−1$ до $t=1$, зауваживши, що $h(t)$ (для $t < τ$) має як нащадків як $o(t)$, так і $h(t+1)$. Його градієнт визначається як:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/6.png\">\n",
    "</center>\n",
    "\n",
    "Після отримання градієнтів на внутрішніх вузлах обчислювального графа ми можемо отримати градієнти на вузлах параметрів. Розрахунок градієнта з використанням ланцюгового правила для всіх параметрів:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/7.png\">\n",
    "</center>\n",
    "\n",
    "### Unrolling RNNs in Time\n",
    "\n",
    "Щоб краще зрозуміти RNN, часто корисно «розгорнути» його на кілька часових кроків. Кожна одиниця в мережі пов’язана з певним часовим кроком і приймає як вхідні дані попередньої одиниці (з попереднього часового кроку) разом із поточним входом. Цей процес передачі інформації вздовж кроків у часі дозволяє RNN ефективно моделювати послідовні дані.\n",
    "\n",
    "### Forward Pass, Backward Pass (Backpropagation Through Time - BPTT)\n",
    "\n",
    "Навчання RNN передбачає прохід вперед, де ми обчислюємо вихідні дані з урахуванням поточних вхідних даних і станів, після чого слід прохід назад, де ми регулюємо ваги за допомогою градієнтного спуску. Цей процес дещо складніший, ніж у мережах прямого зв’язку через тимчасові з’єднання. Алгоритм, який використовується для цього, називається зворотним розповсюдженням у часі (Backpropagation Through Time - BPTT), розширенням стандартного зворотного розповсюдження, що використовується в інших нейронних мережах.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/btt.png\" height=300, width=500>\n",
    "</center>\n",
    "\n",
    "BPTT працює, розгортаючи RNN з часом, створюючи ряд взаємопов’язаних мереж прямого зв’язку. Кожен часовий крок відповідає одному шару в цій розгорнутій мережі, а ваги між шарами розподіляються між часовими кроками. Розгорнуту мережу можна розглядати як дуже глибоку мережу прямого зв’язку, де ваги розподіляються між шарами.\n",
    "\n",
    "Під час навчання помилка поширюється через розгорнуту мережу, а ваги оновлюються за допомогою градієнтного спуску. Це дозволяє мережі навчитися прогнозувати вихід на кожному кроці часу на основі вхідних даних на цьому кроці часу, а також на попередніх кроках часу.\n",
    "\n",
    "Однак BPTT має певні труднощі, такі як проблема зникнення градієнта, коли градієнти стають дуже малими, коли вони поширюються назад у часі, що ускладнює вивчення довгострокових залежностей. Щоб вирішити цю проблему, були запропоновані різні модифікації BPTT, такі як усічене зворотне поширення в часі та градієнтне відсікання.\n",
    "\n",
    "### Challenges: Gradient Vanishing and Exploding\n",
    "\n",
    "Незважаючи на свій потенціал, RNN не позбавлені викликів. Найпомітнішими проблемами є проблеми зникнення та вибухового градієнта. Це відноситься до явищ, коли під час навчання градієнти можуть стати занадто малими (зникнути) або занадто великими (вибухнути), що ускладнює навчання мережі. Для пом’якшення цих проблем було розроблено різні стратегії та вдосконалені архітектури.\n",
    "\n",
    "BPTT потребує обчислень і може страждати від проблеми зникнення або вибуху градієнта, особливо для довгих послідовностей. Це робить навчання RNN з BPTT складним для довгих послідовностей. Такі методи, як відсікання градієнта або використання передових архітектур, таких як LSTM і GRU, можуть допомогти пом’якшити ці проблеми.\n",
    "\n",
    "Переваги та недоліки типової архітектури RNN підсумовано в таблиці нижче:\n",
    "\n",
    "| Переваги                                                        | Недоліки                                                            |\n",
    "|-----------------------------------------------------------------|---------------------------------------------------------------------|\n",
    "| • Можливість обробки вхідних даних будь-якої довжини            | • Обчислення повільні                                               |\n",
    "| • Розмір моделі не збільшується разом із розміром вхідних даних | • Труднощі з доступом до інформації давнього часу                   |\n",
    "| • Розрахунок враховує історичну інформацію                      | • Неможливо розглянути будь-який майбутній вхід для поточного стану |\n",
    "| • Вага розподіляється в часі\t                                  |                                                                     |\n",
    "\n",
    "Хоча в принципі RNN є простою та потужною моделлю, на практиці її важко правильно навчити. Серед основних причин, чому ця модель така громіздка, – проблеми з градієнтом, що зникає, і градієнтом, що вибухає.\n",
    "\n",
    "У той час як вибухаючий градієнт можна виправити за допомогою техніки відсікання градієнта ([gradient clipping](https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html)), проблема зникнення градієнта все ще є основною проблемою для RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50494065-1293-4a3c-b8c1-361b5c5ee058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Влад та Оксана поїхали в Карпати.\"\n",
    "\n",
    "Влад -> NER (name)\n",
    "\n",
    "та -> Null\n",
    "\n",
    "Оксана -> NER (name)\n",
    "\n",
    "поїхали -> Null\n",
    " \n",
    "в -> Null\n",
    "\n",
    "Карпати -> NER (place)\n",
    "\n",
    "\"Цей товар мені спододобався.\"\n",
    "\n",
    "x1: Цей -> \n",
    "\n",
    "x2: товар -> \n",
    "\n",
    "x3: мені ->\n",
    "\n",
    "x4: сподобався -> 1 (good) / 0 (bad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3d33f3-12b9-49ba-a663-8acbfb4b335a",
   "metadata": {},
   "source": [
    "## Applications of RNNs\n",
    "\n",
    "Моделі RNN в основному використовуються в області обробки природної мови та розпізнавання мовлення. Різні варіації підсумовано в таблиці нижче:\n",
    "\n",
    "\n",
    "| Type of RNN                       |  Illustration                                                              | Example                    |\n",
    "|:---------------------------------:|:--------------------------------------------------------------------------:|:--------------------------:|\n",
    "| One-to-one<br>$T_x = T_y = 1$     | <img src=\"assets/rnn-one-to-one-ltr.png\" height=200 width=400>             | Traditional neural network |\n",
    "| One-to-many<br>$T_x = 1, T_y > 1$ | <img src=\"assets/rnn-one-to-many-ltr.png\" height=200 width=400>            | Music generation           |\n",
    "| Many-to-one<br>$T_x > 1, T_y = 1$ | <img src=\"assets/rnn-many-to-one-ltr.png\" height=200 width=400>            | Sentiment classification   |\n",
    "| Many-to-many<br>$T_x = T_y$       | <img src=\"assets/rnn-many-to-many-same-ltr.png\" height=200 width=400>      | Named entity recognition   |\n",
    "| Many-to-many<br>$T_x \\ne T_y$     | <img src=\"assets/rnn-many-to-many-different-ltr.png\" height=200 width=400> | Machine translation        |\n",
    "\n",
    "#### One-to-Many\n",
    "\n",
    "Рекурентні нейронні мережі (RNN) з одного до багатьох (One-to-Many) є одним з типів архітектур RNN, де вхідна послідовність подається в модель, і для кожного елемента цієї послідовності генерується вихідна послідовність. Це означає, що модель отримує одне вхідне значення і генерує послідовність вихідних значень.\n",
    "\n",
    "Основна ідея за такою архітектурою полягає в тому, що модель може взаємодіяти з вхідною інформацією і генерувати відповідні вихідні значення для кожного елемента послідовності. Це може бути корисним в різних задачах, таких як генерація тексту, музики або відео.\n",
    "\n",
    "#### Many-to-One\n",
    "\n",
    "Рекурентні нейронні мережі (RNN) типу Many-to-One - це архітектурний тип, призначений для обробки послідовностей, де кілька вхідних елементів подаються в модель, і в результаті генерується одне вихідне значення.\n",
    "\n",
    "Основна ідея за такою архітектурою полягає в тому, що модель отримує послідовність вхідних значень і виробляє вихідне значення, яке може бути використане, наприклад, для класифікації чи регресії.\n",
    "\n",
    "Однією з типових задач для Many-to-One RNN є аналіз тексту або послідовності, де модель може приймати послідовність слів або символів і генерувати вихідне значення, таке як клас категорії або сентименту. В інших випадках, наприклад, в медичній області, Many-to-One RNN може використовуватися для аналізу часових рядів сигналів з датчиків та прогнозування певного стану.\n",
    "\n",
    "#### Many-to-Many\n",
    "\n",
    "Мережі Many-to-Many в контексті рекурентних нейронних мереж (RNN) включають в себе вхід і вихід на кожному часовому кроці. Це означає, що модель отримує послідовність вхідних даних і генерує відповідну послідовність вихідних даних. Цей тип архітектури може використовуватися для різних завдань, і особливо цікавим є випадок Many-to-Many з однаковою довжиною вхідної і вихідної послідовностей.\n",
    "\n",
    "Існує декілька підтипів Many-to-Many RNN:\n",
    "\n",
    "1. **Many-to-Many (з різними довжинами):** У цьому випадку довжина вхідної послідовності може відрізнятися від довжини вихідної послідовності. Такі моделі можуть використовуватися для завдань, де важливо враховувати контекст вхідної послідовності і генерувати відповідь в різних розмірах.\n",
    "\n",
    "2. **Many-to-Many (з однаковою довжиною):** Цей варіант використовується, коли довжина вхідної послідовності дорівнює довжині вихідної. Такі моделі можуть використовуватися для задач, де кожен елемент вхідної послідовності має відповідний вихід, наприклад, у випадку сегментації часових рядів.\n",
    "\n",
    "3. **Many-to-Many (з затримкою):** В даній модифікації вихід генерується з певною затримкою відносно входу. Це може бути корисно в задачах, де важливо передбачати події з певним відступом від вхідних даних.\n",
    "\n",
    "Застосування Many-to-Many RNN може включати в себе такі завдання, як:\n",
    "\n",
    "- **Часова серія та прогнозування:** Прогнозування значень часових рядів на основі попередніх значень.\n",
    "- **Сегментація об'єктів в зображеннях:** Призначення класів кожному пікселю зображення.\n",
    "- **Розпізнавання мовлення:** Визначення фонем або фонетичних одиниць у вимовленні.\n",
    "\n",
    "У залежності від конкретного завдання та характеристик даних може використовуватися різноманітні архітектури RNN, такі як LSTM, GRU або більш сучасні архітектури, такі як Transformer.\n",
    "\n",
    "#### Many-to-Many (NER)\n",
    "\n",
    "RNN типу Many-to-Many, зокрема в контексті завдання розпізнавання іменованих сутностей (Named Entity Recognition, NER), представляє собою архітектурний підхід, при якому модель отримує послідовність вхідних елементів і генерує вихідну послідовність, де кожен вихідний елемент відповідає вхідному елементу та вказує на його клас або категорію іменованої сутності.\n",
    "\n",
    "Для задачі NER, де метою є виявлення та класифікація іменованих сутностей, таких як особи, місця, дати та інші ключові елементи в тексті, Many-to-Many RNN може виявитися ефективним варіантом. Кожен часовий крок в вихідній послідовності моделі може вказувати на клас іменованої сутності або тег, що відповідає конкретному елементу вхідної послідовності.\n",
    "\n",
    "NER, або розпізнавання іменованих сутностей (англ. Named Entity Recognition), є видом задачі в обробці природної мови (NLP). Це техніка, спрямована на виявлення та класифікацію іменованих сутностей у тексті, таких як імена осіб, назви компаній, локації, дати, числа, адреси тощо.\n",
    "\n",
    "Мета NER - автоматизувати процес визначення інформації про конкретні об'єкти в тексті, надаючи контекст та структуру. Наприклад, в реченні \"Apple Inc. була заснована Стівом Джобсом у Купертіно, Каліфорнія, у 1976 році\", NER може визначити, що \"Apple Inc.\" - це організація, \"Стів Джобс\" - ім'я особи, \"Купертіно, Каліфорнія\" - місцезнаходження, а \"1976 рік\" - дата.\n",
    "\n",
    "Ця технологія є важливою для багатьох застосувань в області обробки мови, таких як аналіз текстів новин, екстракція інформації з документів, покращення пошукових систем та інші завдання, пов'язані з аналізом тексту.\n",
    "\n",
    "#### Many-to-Many (Machine Translation)\n",
    "\n",
    "Many-to-Many RNNs в контексті машинного перекладу використовуються для обробки послідовностей на вході і виході. У машинному перекладі це означає, що модель отримує послідовність токенів (наприклад, слова або підрядки) в одній мові і генерує відповідну послідовність токенів у іншій мові.\n",
    "\n",
    "Такий підхід можна використовувати для перекладу великих текстових документів або коротких речень. Основними складовими Many-to-Many RNN для машинного перекладу є:\n",
    "\n",
    "1. **Кодування (Encoder):** Модель починає з кодування вхідної послідовності (тексту в початковій мові) в вектори фіксованої довжини. Це може бути здійснено за допомогою рекурентного шару, такого як LSTM або GRU, або за допомогою більш складних архітектур, таких як Transformer.\n",
    "\n",
    "2. **Декодування (Decoder):** Після отримання векторного представлення вхідної послідовності модель переходить до декодування. Декодер також може бути рекурентним (використовуючи LSTM, GRU) або використовувати інші архітектури, такі як Transformer. Декодер виробляє послідовність токенів у цільовій мові.\n",
    "\n",
    "3. **Застосування для машинного перекладу:** Основною метою Many-to-Many RNN в контексті машинного перекладу є згенерувати переклад тексту з однієї мови на іншу. Кількість часових кроків у декодері зазвичай відповідає довжині вихідної послідовності.\n",
    "\n",
    "4. **Функція втрат (Loss Function):** Для тренування моделі використовується функція втрат, яка порівнює згенерований вихід з очікуваним вихідом. Зазвичай використовується cross-entropy loss для вимірювання відмінностей між передбачуваними й фактичними токенами.\n",
    "\n",
    "Цей тип RNN може використовувати різні підходи до згорткових шарів (convolutions), механізмів уваги та інших додаткових вдосконалень, щоб поліпшити якість перекладу. Також важливо зазначити, що в останні роки моделі на основі архітектури Transformer стали популярними для завдань машинного перекладу, особливо в контексті великих корпусів тексту.\n",
    "\n",
    "## Loss function\n",
    "\n",
    "У випадку рекурентної нейронної мережі функція втрат $L$ усіх часових кроків визначається на основі втрат на кожному часовому кроці таким чином:\n",
    "\n",
    "$$ L(\\hat{y}, y) = \\sum_{t=1}^{T_y} L(\\hat{y}^{<t>}, y^{<t>})$$\n",
    "\n",
    "Зворотне поширення здійснюється в кожен момент часу. На кроці часу $T$ похідна втрати $L$ відносно вагової матриці $W$ виражається таким чином:\n",
    "\n",
    "$$ \\frac{\\partial L^{(T)}}{\\partial W} = \\sum_{t=1}^{T} \\frac{\\partial L^{(T)}}{\\partial W} \\Bigg|_{(t)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6854319-6f84-4d7d-b735-b0563679a789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15efa278-c5bf-4cf0-abab-89c6fc89619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oleh_komenchuk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oleh_komenchuk/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stopwords_eng = stopwords.words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77599723-4ba6-4ddf-8270-b4b9e298aeb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                               text\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spam.csv\", skiprows=1, usecols=[0, 1], encoding=\"ISO-8859-1\", names=[\"target\", \"text\"])\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17e774d3-c92c-447a-a640-111505b763d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       "  'Ok lar... Joking wif u oni...'],\n",
       " [0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Отримати список текстових документів з колонки \"text\" у DataFrame.\n",
    "documents = df[\"text\"].tolist()\n",
    "\n",
    "# Створити мітки (labels) на основі колонки \"target\" у DataFrame, де \"spam\" відповідає 1, а \"ham\" - 0.\n",
    "labels = df[\"target\"].map({\"spam\": 1, \"ham\": 0}).tolist()\n",
    "\n",
    "# Вивести перші два елементи списку documents та labels для перевірки.\n",
    "documents[:2], labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba5ff1-3015-49e5-a1f9-abefd90387c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Я пішов гуляти з собакою.\" -> 5 words\n",
    "\"<PAD><PAD><PAD>Вона вечеряє.\" -> 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5278af71-6893-4e5d-9da8-01f32580d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Розділити кожен документ на токени (слова), перетворити їх в нижній регістр та вилучити стоп-слова.\n",
    "tokenized_docs = [[tok for tok in nltk.word_tokenize(doc.lower()) if tok not in stopwords_eng] for doc in documents]\n",
    "\n",
    "# Створити словник (vocabulary), що містить усі унікальні слова з усіх документів.\n",
    "vocabulary = list(set(word for doc in tokenized_docs for word in doc))\n",
    "\n",
    "# Створити словник (word_to_idx), який визначає відповідний індекс для кожного слова, додавши йому 1 (враховуючи відсутність <PAD>).\n",
    "word_to_idx = {\"<PAD>\": 0}\n",
    "for idx, word in enumerate(vocabulary):\n",
    "    word_to_idx[word] = idx + 1\n",
    "\n",
    "# Закодувати кожен документ, замінюючи слова їхніми індексами згідно створеного словника (word_to_idx).\n",
    "encoded_docs = [[word_to_idx[word] for word in doc] for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07f67c8-a6a5-45cf-ae39-e3491499be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оголошення класу SpamHamDataset, який є підкласом torch.utils.data.Dataset.\n",
    "class SpamHamDataset(Dataset):\n",
    "    # Конструктор класу, приймає два аргументи: documents (список текстових документів) та labels (список міток).\n",
    "    def __init__(self, documents, labels):\n",
    "        # Перевірка, чи довжина списку documents співпадає з довжиною списку labels.\n",
    "        if len(documents) != len(labels):\n",
    "            raise ValueError(\"Different sizes of documents and labels!\")\n",
    "        \n",
    "        # Ініціалізація властивостей об'єкта класу - documents та labels.\n",
    "        self.documents = documents\n",
    "        self.labels = labels        \n",
    "\n",
    "    # Метод, який повертає довжину датасету (кількість зразків).\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.documents)\n",
    "\n",
    "    # Метод, який повертає зразок датасету за вказаним індексом.\n",
    "    def __getitem__(self, index) -> tuple:\n",
    "        # Отримати текстовий документ за вказаним індексом.\n",
    "        doc = self.documents[index]\n",
    "        # Конвертувати текстовий документ в тензор типу LongTensor (індекси слів).\n",
    "        doc = torch.LongTensor(doc)\n",
    "\n",
    "        # Отримати мітку за вказаним індексом.\n",
    "        label = self.labels[index]\n",
    "        # Конвертувати мітку в тензор типу FloatTensor.\n",
    "        label = torch.FloatTensor([label])\n",
    "\n",
    "        # Повернути кортеж із текстовим документом та його міткою.\n",
    "        return doc, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ec2d75c-cc57-446f-b931-ae1aa01392a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 1115)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Розділення набору даних на тренувальний та тестовий, а також створення об'єктів датасетів.\n",
    "\n",
    "# Розділити закодовані документи та мітки на тренувальний і тестовий набори за допомогою train_test_split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_docs, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Створити об'єкт тренувального датасету, використовуючи клас SpamHamDataset.\n",
    "train_dataset = SpamHamDataset(X_train, y_train)\n",
    "\n",
    "# Створити об'єкт тестового датасету, використовуючи клас SpamHamDataset.\n",
    "test_dataset = SpamHamDataset(X_test, y_test)\n",
    "\n",
    "# Вивести довжину тренувального та тестового датасетів для перевірки.\n",
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "079a09af-6adc-4696-af54-b2d060be990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визначення функції seq_collate_fn для коректного формування батчів у DataLoader.\n",
    "\n",
    "# Функція seq_collate_fn приймає список елементів батча та повертає відформовані дані.\n",
    "def seq_collate_fn(batch):\n",
    "    # Використання pad_sequence для доповнення текстових документів до максимальної довжини в батчі.\n",
    "    # pad_sequence: https://pytorch.org/docs/stable/generated/torch.nn.utils.rnn.pad_sequence.html\n",
    "    xs = pad_sequence([item[0] for item in batch], batch_first=True, padding_value=0)\n",
    "    \n",
    "    # Конвертація міток у тензор типу FloatTensor та додавання додаткового виміру для сумісності з моделлю.\n",
    "    ys = torch.FloatTensor([[item[1]] for item in batch])\n",
    "    \n",
    "    # Повернення відформованих даних у форматі (вхідний тензор xs, вихідний тензор ys).\n",
    "    return xs, ys\n",
    "\n",
    "# Створення DataLoader для тренувального та тестового датасетів з використанням зазначених параметрів.\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=seq_collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=seq_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "514f7381-ebc4-4f28-952f-6f4ab693fe77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3774f6-c907-4005-bb7a-cf18d82641e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оголошення класу SimpleRNN, що є підкласом nn.Module та визначає простий рекурентний шар (RNN).\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    # Конструктор класу, приймає параметри vocab_size (розмір словника), input_size (розмір входу),\n",
    "    # hidden_size (розмір прихованого стану), та output_size (розмір виходу).\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, output_size):\n",
    "        # Виклик конструктора батьківського класу nn.Module.\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        # Вбудовувальний шар (Embedding) для конвертації індексів слів в вектори.\n",
    "        self.embed = nn.Embedding(vocab_size, input_size, padding_idx=0)\n",
    "\n",
    "        # Розміри прихованого стану та визначення рекурентного шару.\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # torch.nn.RNN docs: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        # Лінійний шар для зведення прихованого стану до розміру виходу.\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    # Метод forward, що визначає прямий прохід через модель.\n",
    "    def forward(self, x):  # long tensor [B, T]\n",
    "        # Ініціалізація початкового стану прихованого шару h0.\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size, device=x.device)  # float tensor [1, B, HiddenSize]\n",
    "\n",
    "        # Вбудовування вхідних даних (індексів слів) у вектори.\n",
    "        x = self.embed(x)  # float tensor [B, T, InputSize]\n",
    "\n",
    "        # Прохід через рекурентний шар.\n",
    "        out, _ = self.rnn(x, h0)  # float tensor [B, T, HiddenSize]\n",
    "\n",
    "        # Відібрати максимальні значення по кожному батчу у вихідному тензорі.\n",
    "        out = out.max(1)[0]\n",
    "\n",
    "        # Пройти через лінійний шар для отримання вихідних значень.\n",
    "        out = self.fc(out)  # float tensor [B, OutputSize]\n",
    "\n",
    "        # Повернути вихід моделі.\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4bb49f3-3ccd-4e8f-b0c6-0c3272f41542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device - cpu\n",
      "SimpleRNN(\n",
      "  (embed): Embedding(8863, 512, padding_idx=0)\n",
      "  (rnn): RNN(512, 512, batch_first=True)\n",
      "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
      ")\n",
      "Number of trainable parameters - 5063681\n"
     ]
    }
   ],
   "source": [
    "# Налаштування пристрою, ініціалізація моделі, критерію та оптимізатора.\n",
    "\n",
    "# Визначення пристрою (GPU якщо доступний, інакше CPU).\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device - {device}\")\n",
    "\n",
    "# Встановлення випадкового насіння для відтворюваності.\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Ініціалізація моделі SimpleRNN з вказаною кількістю параметрів.\n",
    "model = SimpleRNN(len(word_to_idx), 512, 512, 1)\n",
    "\n",
    "# Перенесення моделі на вказаний пристрій.\n",
    "model = model.to(device)\n",
    "\n",
    "# Виведення інформації про модель та кількість навчальних параметрів.\n",
    "print(model)\n",
    "print(\"Number of trainable parameters -\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# Визначення критерію (функції втрат) та оптимізатора (Adam) для навчання моделі.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e69501-17a7-4487-9d0d-4d3ecdb03bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  loss: 0.19311953701018805\n",
      "Epoch 2/20\n",
      "  loss: 0.04128904482366444\n",
      "Epoch 3/20\n",
      "  loss: 0.012459575675309411\n",
      "Epoch 4/20\n",
      "  loss: 0.0021390981131075132\n",
      "Epoch 5/20\n",
      "  loss: 0.0007302987444201275\n",
      "Epoch 6/20\n",
      "  loss: 0.0004309399317364335\n",
      "Epoch 7/20\n",
      "  loss: 0.014535952262193726\n",
      "Epoch 8/20\n",
      "  loss: 0.01031796789821884\n",
      "Epoch 9/20\n",
      "  loss: 0.000911190240913129\n",
      "Epoch 10/20\n",
      "  loss: 0.0002536368425057192\n",
      "Epoch 11/20\n",
      "  loss: 0.00016343451591712836\n",
      "Epoch 12/20\n",
      "  loss: 0.00011839837037276794\n",
      "Epoch 13/20\n",
      "  loss: 9.099522999088787e-05\n",
      "Epoch 14/20\n",
      "  loss: 7.151458651717584e-05\n",
      "Epoch 15/20\n",
      "  loss: 5.735925714439892e-05\n",
      "Epoch 16/20\n",
      "  loss: 4.6945780243040775e-05\n",
      "Epoch 17/20\n",
      "  loss: 3.868831418590308e-05\n",
      "Epoch 18/20\n",
      "  loss: 3.415915400767853e-05\n",
      "Epoch 19/20\n",
      "  loss: 2.6791430657120203e-05\n",
      "Epoch 20/20\n",
      "  loss: 2.2457465711031088e-05\n"
     ]
    }
   ],
   "source": [
    "# Навчання моделі за допомогою циклу ітерацій по епохах та батчам.\n",
    "\n",
    "# Визначення кількості епох та створення порожнього списку для відстеження втрат на тренувальному наборі.\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "\n",
    "# Цикл по епохах.\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "\n",
    "    # Створення порожнього списку для зберігання втрат на кожному батчі.\n",
    "    losses = []\n",
    "\n",
    "    # Цикл по батчам у тренувальному DataLoader.\n",
    "    for i, (docs, labels) in enumerate(train_loader):\n",
    "        # Обнулення градієнтів параметрів моделі перед кожним батчем.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Переміщення вхідних даних та міток на вказаний пристрій.\n",
    "        docs = docs.to(device)\n",
    "        outputs = model(docs)\n",
    "\n",
    "        # Визначення значення функції втрат та здійснення зворотнього поширення градієнтів.\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # Оптимізація параметрів моделі згідно з градієнтами.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Зберігання значення втрат на поточному батчі.\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Зберігання середнього значення втрат на кожній епохі для подальшого відстеження.\n",
    "    train_losses.append(np.mean(losses))\n",
    "    print(f\"  loss: {train_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30a7e115-42fa-4be2-a930-2bc6a65d165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98       966\n",
      "         1.0       0.85      0.92      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.92      0.95      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Accuracy: 0.967713004484305\n"
     ]
    }
   ],
   "source": [
    "# Оцінка моделі на тестовому наборі та виведення метрик класифікації.\n",
    "\n",
    "# Перевстановлення моделі у режим інференсу (evaluation).\n",
    "model.eval()\n",
    "\n",
    "# Створення порожніх списків для зберігання прогнозів та міток з тестового набору.\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Використання контекстного менеджера torch.no_grad() для вимкнення обчислення градієнтів під час інференсу.\n",
    "with torch.no_grad():\n",
    "    # Цикл по батчам у тестовому DataLoader.\n",
    "    for docs, labels in test_loader:\n",
    "        # Отримання вихідних значень моделі для вхідних даних з тестового батчу.\n",
    "        outputs = model(docs.to(device))\n",
    "\n",
    "        # Застосування сигмоїдальної функції та порогового значення для отримання бінарних прогнозів.\n",
    "        preds = (outputs.sigmoid() >= 0.5).long().detach().cpu()\n",
    "\n",
    "        # Розширення списків з прогнозами та мітками.\n",
    "        all_preds.extend(preds.numpy()[:, 0])\n",
    "        all_labels.extend(labels.numpy()[:, 0])\n",
    "\n",
    "# Виведення звіту про класифікацію та точності на тестовому наборі.\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print('Accuracy:', accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db23872-311a-409a-9188-78f6d5caf860",
   "metadata": {},
   "source": [
    "## [Long Short-Term Memory](https://www.bioinf.jku.at/publications/older/2604.pdf)\n",
    "\n",
    "LSTM — це особливий вид рекурентної нейронної мережі, здатної вивчати довгострокові залежності, що є досить складним для традиційних RNN через проблему зникаючого градієнта. Вони були представлені Зеппом Хохрайтером і Юргеном Шмідхубером у 1997 році.\n",
    "\n",
    "LSTM характеризується станом комірки, який проходить через блоки, і трьома воротами, що регулюють потік інформації всередині блоку LSTM: вхідним, забутим і вихідним. Ось компоненти, пояснені більш детально:\n",
    "\n",
    "- **Cell State** ($C_t$): Це «пам’ять» блоку, яка переносить інформацію через часові кроки.\n",
    "- **Input Gate** ($i_t$): Цей \"gate\" (\"ворота\") вирішує, яку інформацію слід зберігати в стані комірки.\n",
    "- **Forget Gate** ($f_t$): Цей \"gate\" (\"ворота\") вирішує, яка інформація повинна бути відкинута зі стану комірки.\n",
    "- **Output Gate** ($o_t$): Цей \"gate\" (\"ворота\") вирішує, яка інформація повинна бути виведена на цьому кроці часу.\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/lstm.png\" height=300 width=600>\n",
    "</center>\n",
    "\n",
    "Математичні операції на кожному кроці часу в LSTM такі:\n",
    "\n",
    "- **Forget gate:**\n",
    "$$ f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f) $$\n",
    "\n",
    "- **Input gate:**\n",
    "$$ i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i) $$\n",
    "\n",
    "- **Cell state:**\n",
    "$$ \\hat{C}_t = \\tanh(W_c \\cdot [h_{t-1}, x_t] + b_C) $$\n",
    "$$ C_t = f_t \\odot C_{t-1} + i_t \\odot \\hat{C}_t $$\n",
    "\n",
    "- **Output gate:**\n",
    "$$ o_t = \\sigma (W_o \\cdot [h_{t-1}, x_t] + b_o) $$\n",
    "$$ h_t = o_t \\odot \\tanh(C_t) $$\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/lstm_2.png\" height=400 width=900>\n",
    "</center>\n",
    "\n",
    "Тут:\n",
    "- $x_t$ - введення (input) на кроці часу $t$\n",
    "- $h_{t-1}$ - прихований стан на кроці часу $t-1$\n",
    "- $C_{t-1}$ - стан комірки на кроці часу $t-1$\n",
    "- $W_f, W_i, W_C, W_o$ - вагові матриці, $b_f, b_f, b_C, b_o$ - вектори зміщення\n",
    "- $\\odot$ - поелементне множення\n",
    "\n",
    "Інформаційний потік:\n",
    "- **Step 1 (Forget Fate):** По-перше, gate забуття вирішує, яку інформацію ми будемо викидати зі стану комірки.\n",
    "- **Step 2 (Input Gate and Cell State):** Далі вхідний gate вирішує, які значення ми будемо оновлювати у стані клітинки. Потім шар $\\tanh$ створює нові значення-кандидати $C_t$, які можна додати до стану. На наступному кроці ми об’єднуємо ці два, щоб створити оновлення стану.\n",
    "- **Step 3 (Output Gate and Final State):** Нарешті, ми вирішуємо, що будемо виводити. Цей вихід базуватиметься на стані нашої комірки, але буде відфільтрованою версією."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9adfdb-9dad-4360-9a5b-b3516b0b5b0a",
   "metadata": {},
   "source": [
    "\n",
    "## [Gated Recurrrent Unit](https://arxiv.org/abs/1406.1078v3)\n",
    "GRU є розширенням традиційної рекурентної нейронної мережі, яка має на меті вирішити деякі проблеми, пов’язані з основними RNN, наприклад труднощі з вивченням довгострокових залежностей через проблему зникаючого градієнта.\n",
    "\n",
    "GRU є варіантом довготривалої короткочасної пам’яті (LSTM) і був представлений не тільки для боротьби з проблемою зникнення градієнта, але й для спрощення архітектури моделі. Як і LSTM, GRU здатні ефективно фіксувати залежності для послідовностей різної довжини.\n",
    "\n",
    "Рівень GRU складається з кількох компонентів і блоків, які контролюють потік інформації, яку потрібно запам’ятати або забути на кожному кроці часу. Основними компонентами GRU є:\n",
    "\n",
    "<center>\n",
    "    <img src=\"assets/gru.png\" height=400 width=800>\n",
    "</center>\n",
    "\n",
    "1. **Reset Gate:** ($r_t$) Це визначає, скільки минулої інформації потрібно передати в майбутнє.\n",
    "2. **Update Gate:** ($z_t$) Це визначає, скільки минулої інформації потрібно передати на вихід.\n",
    "3. **New Memory Content:** ($\\hat{h}_t$) Він містить значення-кандидати, які можна додати до внутрішньої пам’яті або стану.\n",
    "4. **Hidden State:** (h_t) Це являє собою пам'ять одиниці, яка передається через часові кроки.\n",
    "\n",
    "Тут:\n",
    " - $x_t$ - введення (input) за часом $t$\n",
    " - $h_{t-1}$ - прихований стан на кроці часу $t-1$\n",
    " - $z_t$ - оновлювати вектор воріт за раз $t$\n",
    " - $r_t$ - скинути вектор воріт за один раз $t$\n",
    " - $W_z, W_r, W$ - вагові матриці, $b_z, b_r, b$ - вектори зміщення\n",
    " - $\\odot$ - поелементне множення\n",
    "\n",
    "Інформаційний потік:\n",
    "- **Step 1 (Update and Reset Gates):** По-перше, gates оновлення та скидання вирішують, яку інформацію викинути, а яку нову додати.\n",
    "- **Step 2 (New Memory Content):** Далі gate скидання використовується для обчислення нового вмісту пам’яті, який є кандидатом на новий стан пристрою.\n",
    "- **Step 3 (Hidden State):** Нарешті, gate оновлення використовується для обчислення того, скільки минулої інформації потрібно передати в майбутнє."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b6e28-a86c-4c72-87af-a394de452ffb",
   "metadata": {},
   "source": [
    "### GRU vs LSTM\n",
    "\n",
    "GRU (Gated Recurrent Unit) і LSTM (Long Short-Term Memory) - це два типи рекурентних нейронних мереж (RNN), які використовуються для обробки послідовностей даних. Обидві мають спеціальні механізми, що дозволяють контролювати потік інформації в середині мережі, але вони мають кілька відмінностей:\n",
    "\n",
    "1. **Архітектура воріт:** У LSTM є троє основних воріт: ворота забування (forget gate), ворота входу (input gate) і ворота виходу (output gate). У GRU є двоє воріт: ворота забування/оновлення (update gate) і ворота виходу.\n",
    "\n",
    "2. **Кількість параметрів:** GRU має менше параметрів, оскільки він має менше воріт. Це може зробити GRU більш швидким у тренуванні та менш вимогливим до обчислювальних ресурсів.\n",
    "\n",
    "3. **Швидкість тренування та виконання:** Через меншу кількість параметрів GRU може тренуватися швидше та працювати швидше в порівнянні з LSTM.\n",
    "\n",
    "4. **Можливість \"забуття\" інформації:** У LSTM є окремі ворота забування, що дозволяє мережі вирішувати, яку інформацію забути або зберегти в пам'яті. У GRU ворота забування і ворота оновлення об'єднані, що дозволяє GRU швидше адаптуватися до нових вхідних даних."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88541ea0-0df2-464d-a4e5-52d3483355ed",
   "metadata": {},
   "source": [
    "## Variants of RNNs\n",
    "\n",
    "| Bidirectional (BRNN) | Deep (DRNN) |\n",
    "|:--------------------:|:-----------:|\n",
    "| <img src=\"assets/bidirectional-rnn-ltr.png\" height=200 width=400> | <img src=\"assets/deep-rnn-ltr.png\" height=200 width=400> |\n",
    "\n",
    "**Bidirectional Recurrent Neural Network (BRNN)** є специфічним типом рекурентної нейронної мережі (RNN), який спрямований в обидві сторони часового виміру. Основна ідея BRNN полягає в тому, що для кожного моменту часу мережа обробляє інформацію з попередніх та наступних моментів часу, враховуючи контекст як зліва, так і справа від поточного моменту.\n",
    "\n",
    "Основні характеристики BRNN:\n",
    "\n",
    "1. **Архітектура:**\n",
    "   - **Прямий та зворотний прохід:** BRNN складається з двох частин: одна частина обробляє дані від початку до кінця послідовності (прямий прохід), а інша - від кінця до початку (зворотний прохід).\n",
    "   - **Об'єднання результатів:** Вихідні результати обох проходів об'єднуються, наприклад, шляхом конкатенації векторів або застосування якоїсь іншої операції об'єднання.\n",
    "\n",
    "2. **Застосування:**\n",
    "   - **Машинний переклад:** BRNN може бути ефективним у вирішенні завдань машинного перекладу, оскільки важливо враховувати контекст як зліва, так і справа від поточного слова для правильного перекладу.\n",
    "   - **Обробка мовлення:** У завданнях обробки мовлення, таких як розпізнавання мови або аналіз настрою тексту, BRNN може допомагати у виявленні важливих патернів та контексту.\n",
    "\n",
    "3. **Переваги:**\n",
    "   - **Контекстуальне розуміння:** BRNN надає моделі можливість отримати контекст як з минулого, так і з майбутнього, що допомагає в розумінні та узагальненні вхідних даних.\n",
    "   - **Покращення в якості прогнозів:** Завдяки доступу до інформації з обох сторін вхідної послідовності BRNN може вирізнятися в завданнях, де важливий контекст з обох напрямків.\n",
    "\n",
    "BRNN може бути використаний в різних областях і завданнях, де важливо враховувати ширший контекст і покращити розуміння вхідних даних.\n",
    "\n",
    "**Deep Recurrent Neural Network (DRNN)** - це тип нейронної мережі, яка має кілька шарів рекурентної нейронної мережі (RNN).\n",
    "\n",
    "Основна відмінність між DRNN та звичайними RNN полягає в тому, що DRNN мають кілька шарів RNN. Це дозволяє DRNN краще обробляти довгострокові залежності в послідовних даних.\n",
    "\n",
    "DRNN можна побудувати різними способами. Один з поширених способів полягає в тому, щоб використовувати звичайні RNN в якості шарів DRNN. Інший спосіб полягає в тому, щоб використовувати спеціальні типи RNN, такі як довготермінові короткострокові пам'яті (LSTM) або мережі зворотного зв'язку з пам'яттю (GRU).\n",
    "\n",
    "DRNN мають ряд переваг перед звичайними RNN. Вони можуть краще обробляти довгострокові залежності, що робить їх придатними для таких завдань, як переклад та розпізнавання мови. Крім того, DRNN можуть бути більш ефективними в обчисленні, ніж звичайні RNN.\n",
    "\n",
    "Ось деякі з прикладів того, як DRNN можна використовувати:\n",
    "\n",
    "* **Переклад:** DRNN можна використовувати для перекладу тексту з однієї мови на іншу. Для цього DRNN навчаються на наборі даних, що містить текст у двох мовах.\n",
    "* **Розпізнавання мови:** DRNN можна використовувати для розпізнавання мови. Для цього DRNN навчаються на наборі даних, що містить аудіофайли та їх транскрипції.\n",
    "* **Синтез мови:** DRNN можна використовувати для синтезу мови. Для цього DRNN навчаються на наборі даних, що містить текст і аудіофайли.\n",
    "* **Обробка природної мови:** DRNN можна використовувати для таких завдань обробки природної мови, як класифікація тексту, відповіді на запитання та створення резюме.\n",
    "\n",
    "DRNN є потужним інструментом, який можна використовувати для вирішення різноманітних завдань, пов'язаних з обробкою послідовних даних."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9437bd71-8adb-4b0c-b6a2-4b88e69e9d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Додання класу SimpleGRU, який є підкласом nn.Module та визначає простий GRU шар.\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    # Конструктор класу, приймає параметри vocab_size (розмір словника), input_size (розмір входу),\n",
    "    # hidden_size (розмір прихованого стану), та output_size (розмір виходу).\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, output_size):\n",
    "        # Виклик конструктора батьківського класу nn.Module.\n",
    "        super(SimpleGRU, self).__init__()\n",
    "\n",
    "        # Вбудовувальний шар (Embedding) для конвертації індексів слів в вектори.\n",
    "        self.embed = nn.Embedding(vocab_size, input_size, padding_idx=0)\n",
    "\n",
    "        # Визначення GRU шару з 5 шарами, двостороннім (bidirectional) та вказанням batch_first=True.\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers=5, bidirectional=True, batch_first=True)\n",
    "\n",
    "        # Лінійний шар для зведення прихованого стану до розміру виходу.\n",
    "        self.fc = nn.Linear(hidden_size * 2, output_size)\n",
    "\n",
    "    # Метод forward, що визначає прямий прохід через модель.\n",
    "    def forward(self, x):  # long tensor [B, T]\n",
    "        # Вбудовування вхідних даних (індексів слів) у вектори.\n",
    "        x = self.embed(x)  # float tensor [B, T, InputSize]\n",
    "\n",
    "        # Прохід через GRU шар.\n",
    "        out, _ = self.gru(x)  # float tensor [B, T, HiddenSize]\n",
    "\n",
    "        # Підрахунок середнього значення по часовій вісі для отримання одного вектору на кожний батч.\n",
    "        out = out.mean(1)\n",
    "\n",
    "        # Пройти через лінійний шар для отримання вихідних значень.\n",
    "        out = self.fc(out)  # float tensor [B, OutputSize]\n",
    "\n",
    "        # Повернути вихід моделі.\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a8c1bad-70f8-4ff9-9621-e4cca17a5ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device - cpu\n",
      "SimpleGRU(\n",
      "  (embed): Embedding(8863, 16, padding_idx=0)\n",
      "  (gru): GRU(16, 16, num_layers=5, batch_first=True, bidirectional=True)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      ")\n",
      "Number of trainable parameters - 164305\n"
     ]
    }
   ],
   "source": [
    "# Налаштування пристрою, ініціалізація моделі, критерію та оптимізатора для SimpleGRU.\n",
    "\n",
    "# Визначення пристрою (GPU якщо доступний, інакше CPU).\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device - {device}\")\n",
    "\n",
    "# Встановлення випадкового насіння для відтворюваності.\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Ініціалізація моделі SimpleGRU з вказаною кількістю параметрів.\n",
    "model = SimpleGRU(len(word_to_idx), 16, 16, 1)\n",
    "\n",
    "# Перенесення моделі на вказаний пристрій.\n",
    "model = model.to(device)\n",
    "\n",
    "# Виведення інформації про модель та кількість навчальних параметрів.\n",
    "print(model)\n",
    "print(\"Number of trainable parameters -\", sum(p.numel() for p in model.parameters() if p.requires_grad))\n",
    "\n",
    "# Визначення критерію (функції втрат) та оптимізатора (Adam) для навчання моделі.\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e7a3b8c-4bd1-4471-9a9f-91ee3464dba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  loss: 0.3103157473280759\n",
      "Epoch 2/20\n",
      "  loss: 0.16927538275398235\n",
      "Epoch 3/20\n",
      "  loss: 0.1175882682858509\n",
      "Epoch 4/20\n",
      "  loss: 0.09092878749240256\n",
      "Epoch 5/20\n",
      "  loss: 0.06533884535640425\n",
      "Epoch 6/20\n",
      "  loss: 0.04961363203977118\n",
      "Epoch 7/20\n",
      "  loss: 0.03771707659176681\n",
      "Epoch 8/20\n",
      "  loss: 0.027984439030683542\n",
      "Epoch 9/20\n",
      "  loss: 0.02179249063698328\n",
      "Epoch 10/20\n",
      "  loss: 0.022967674919257216\n",
      "Epoch 11/20\n",
      "  loss: 0.02353412134899995\n",
      "Epoch 12/20\n",
      "  loss: 0.01618846099261248\n",
      "Epoch 13/20\n",
      "  loss: 0.01591176808124081\n",
      "Epoch 14/20\n",
      "  loss: 0.009372072257009739\n",
      "Epoch 15/20\n",
      "  loss: 0.00827180898012293\n",
      "Epoch 16/20\n",
      "  loss: 0.006314818024127093\n",
      "Epoch 17/20\n",
      "  loss: 0.004459694017677845\n",
      "Epoch 18/20\n",
      "  loss: 0.014709849530095768\n",
      "Epoch 19/20\n",
      "  loss: 0.00525396528543644\n",
      "Epoch 20/20\n",
      "  loss: 0.004214407206641503\n"
     ]
    }
   ],
   "source": [
    "# Навчання моделі SimpleGRU за допомогою циклу ітерацій по епохах та батчам.\n",
    "\n",
    "# Визначення кількості епох та створення порожнього списку для відстеження втрат на тренувальному наборі.\n",
    "n_epochs = 20\n",
    "train_losses = []\n",
    "\n",
    "# Цикл по епохах.\n",
    "for epoch in range(n_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{n_epochs}\")\n",
    "\n",
    "    # Створення порожнього списку для зберігання втрат на кожному батчі.\n",
    "    losses = []\n",
    "\n",
    "    # Цикл по батчам у тренувальному DataLoader.\n",
    "    for i, (docs, labels) in enumerate(train_loader):\n",
    "        # Обнулення градієнтів параметрів моделі перед кожним батчем.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Переміщення вхідних даних та міток на вказаний пристрій.\n",
    "        docs = docs.to(device)\n",
    "        outputs = model(docs)\n",
    "\n",
    "        # Визначення значення функції втрат та здійснення зворотнього поширення градієнтів.\n",
    "        loss = criterion(outputs, labels.to(device))\n",
    "        loss.backward()\n",
    "\n",
    "        # Оптимізація параметрів моделі згідно з градієнтами.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Зберігання значення втрат на поточному батчі.\n",
    "        losses.append(loss.item())\n",
    "\n",
    "    # Зберігання середнього значення втрат на кожній епохі для подальшого відстеження.\n",
    "    train_losses.append(np.mean(losses))\n",
    "    print(f\"  loss: {train_losses[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b9842a2-c4c0-4c48-88d6-087f8fc86f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98       966\n",
      "         1.0       0.87      0.89      0.88       149\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.93      0.93      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n",
      "Accuracy: 0.9668161434977578\n"
     ]
    }
   ],
   "source": [
    "# Оцінка моделі SimpleGRU на тестовому наборі та виведення метрик класифікації.\n",
    "\n",
    "# Перевстановлення моделі у режим інференсу (evaluation).\n",
    "model.eval()\n",
    "\n",
    "# Створення порожніх списків для зберігання прогнозів та міток з тестового набору.\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Використання контекстного менеджера torch.no_grad() для вимкнення обчислення градієнтів під час інференсу.\n",
    "with torch.no_grad():\n",
    "    # Цикл по батчам у тестовому DataLoader.\n",
    "    for docs, labels in test_loader:\n",
    "        # Отримання вихідних значень моделі для вхідних даних з тестового батчу.\n",
    "        outputs = model(docs.to(device))\n",
    "\n",
    "        # Застосування сигмоїдальної функції та порогового значення для отримання бінарних прогнозів.\n",
    "        preds = (outputs.sigmoid() >= 0.5).long().detach().cpu()\n",
    "\n",
    "        # Розширення списків з прогнозами та мітками.\n",
    "        all_preds.extend(preds.numpy()[:, 0])\n",
    "        all_labels.extend(labels.numpy()[:, 0])\n",
    "\n",
    "# Виведення звіту про класифікацію та точності на тестовому наборі.\n",
    "print(classification_report(all_labels, all_preds))\n",
    "print('Accuracy:', accuracy_score(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be9919",
   "metadata": {},
   "source": [
    "[The Basics of Recurrent Neural Networks (RNNs)](https://pub.towardsai.net/whirlwind-tour-of-rnns-a11effb7808f)\n",
    "\n",
    "[Recurrent Neural Networks cheatsheet](https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-recurrent-neural-networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e3bc0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
